\documentclass{beamer}

\usepackage[beamer]{shortcut}
\usepackage{bibentry}

\graphicspath{{./images/}}
\usepackage[square]{natbib}


\def\keypoint#1{\hspace{0pt plus 1 filll}\textcolor{gray}{#1}}
\def\mycite#1{\keypoint{\small\citep{#1}}}
\def\tT{\widetilde{T}}

\institute{\\ INRIA Saclay}
\author{Dupr√© La Tour T., \textbf{TM}, Mainak J., Gramfort A.}
\title{
	Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals}

\date{
	May 29, 2018
}

\setbeamertemplate{title page}[frame]
\def\extraLogo{}


\begin{document}
	
\begin{frame}
	\titlepage
    \nobibliography{../../library}
\end{frame}

\begin{frame}{Studying brain activity through electromagnetic signals}
    \begin{itemize}
        \item Brain (electrical) activity produces an electromagnetic field.
        \item This can be measured with EEG or MEG.
    \end{itemize}
    
    \begin{columns}[T]
        \column{.5\textwidth}
            \centering
            \includegraphics[height=6em]{eeg}\hskip4em
            \includegraphics[height=6em]{meg}\\
            \includegraphics[height=8em]{scale_electro}
        \column{.5\textwidth}
            \vskip3em
            \hskip2em
            \includegraphics[height=8em]{multivariate_eeg}
    \end{columns}
\end{frame}

\begin{frame}{Goal: Study Oscillation in Neural Data}

    \textbf{}Oscillations are believed to play an important role in cognitive functions.\\[3em]
    Many studies rely on Fourier or wavelet analyses:\\[.5em]
    \begin{itemize}\itemsep1em
    \item Easy interpretation,
    \item Standard analysis \eg{} canonical bands alpha, beta or theta.\\\mycite{buzsaki2006rhythms}
    \end{itemize}

\end{frame}

\begin{frame}{Goal: Study Oscillation in Neural Data}

However, some brain rhythms are not sinusoidal, \eg mu-waves\mycite{hari2006action}\\
\hskip5em\includegraphics[width=.7\textwidth]{waveform}\\
and filtering degrades waveforms\\
\hskip8em\includegraphics[width=.5\textwidth]{filtering_brain}

\vskip1em
The shape of the waveform can be linked to the information flow between neurons.


\strongpoint{Can extract them with an unsupervised data-driven approach?}
\end{frame}


\begin{frame}{Extracting shift invariant patterns}
\textbf{Key idea}: decouple the localization of the patterns and their shape
\includegraphics[width=\textwidth]{csc_explain_color.png}
\only<2>{
\vskip-2em
\begin{columns}[T]
\column{.3\textwidth}\vskip2em\centering\textbf{Convolutional\\Representation:} %
\column{.7\textwidth}\centering\includegraphics[width=.7\textwidth]{eq_csc_explain_color}
\end{columns}
}
\uncover<3>{
\vskip-2em
\begin{columns}[T]
\column{.3\textwidth}\vskip2em\centering\textbf{Convolutional Dictionary Learning:} %
\column{.7\textwidth}\vskip-.5em\includegraphics[width=\textwidth]{csc_eq_l1}
\end{columns}
}
\end{frame}


%\begin{frame}{Convolutional Dictionary Learning}
%
%\textbf{\large Convolutional Dictionary Learning (CDL)}\mycite{Grosse2007}\\
%For a set of $N$ univariate signals $x^n$, solve
%\begin{equation}
%\label{eq:csc}
%\min_{d_k, z_k^n} \sum_{n=1}^N  \frac{1}{2}\|x^n - \sum_{k=1}^K z_k^n * d_k\|_2^2
%+ \lambda\sum_{k=1}^K\|z^n_k\|_1
%\end{equation}
%\vskip1em
%\textbf{Hypothesis:} patterns $d_k$ are not present everywhere in the signal. They are localized in time.
%\strongpoint{Sparse activation signals $z$}
%\vskip2em
%\textbf{Extra hypothesis:} the patterns are in the $\ell_2$-ball: $\|d_k\|_2^2 \le 1$.
%\end{frame}
%
%
%\begin{frame}{Optimization strategy}
%    \textbf{Bi-convex:} The problem is not jointly convex in $z^n_k$, and  $d_k$
%    but it is convex in each block of coordinate.\\[1em]
%    
%    \textbf{Alternate minimization} (\emph{a.k.a.} Bloc Coordinate Descent):\\[.5em]
%    
%    \begin{itemize}\itemsep1em
%    \item \textbf{Z-step:} given a fixed estimate of the atom, compute the activation signal $z^n_k$ associated to each signal $X^n$.
%    \item \textbf{D-step:} given a fixed estimate of the activation, update the atoms in the dictionary $d_k$.
%    \end{itemize}
%\end{frame}
%
%
%\begin{frame}{How to extend CSC to multivariate signals?}
%We can just use multivariate convolution,
%\[
%	\underbrace{X[t]}_{\in\Rset^P} = \sum_{k=1}^K \left(z_k * D_k\right)[t] = \sum_{k=1}^K \sum_{\tau=1}^L z_k[t-\tau] \underbrace{D_k[\tau]}_{\in \Rset^P}
%\]
%with:
%\begin{itemize}
%	\item $X$ a multivariate signal of length $T$ in $\Rset^P$
%	\item $D_k$ a multivariate signal of length $L$ in $\Rset^P$
%	\item $z_k$ a univariate activation signal of length $\tT = T - L + 1$
%\end{itemize}
%\vskip1em
%However, this model does not account for the physics of the problem.
%\end{frame}

\begin{frame}{EM wave diffusion}
	\begin{itemize}
		\uncover<1->{\item Recording here with 8 sensors}
		\uncover<2->{\item EM activity in the brain}
		\uncover<3->{\item The electric field is spread \textbf{linearly} and \textbf{instantaneously} over all sensors (Maxwell equations)}
	\end{itemize}
	\centering
	\only<1>{\includegraphics[width=.5\textwidth]{physic1}}%
	\only<2>{\includegraphics[width=.5\textwidth]{physic2}}%
	\only<3>{\includegraphics[width=.5\textwidth]{physic3}}
\end{frame}

\begin{frame}{Multivariate CSC with rank-1 constraint}
	\textbf{Idea}: Impose a rank-1 constraint on the dictionary atoms $D_k$
	\vskip1em
	To make the problem tractable, we decided to use auxiliary variables $u_k$ and $v_k$ \st{} $D_k = u_kv_k^\top$.
	
	\begin{equation}
	\label{eq:multichannel_csc}
	\begin{split}
	\min_{u_k, v_k, z_k^n} &\sum_{n=1}^N\frac{1}{2}\left\|X^n - \sum_{k=1}^K z^n_k * (u_k^{ } v_k^\top)\right\|_{2}^{2}
	+ \lambda  \sum_{k=1}^K \left\|z^n_k\right\|_1, \hspace{6pt}\\
	&\text{s.t. } ~~ \|u_{k}\|_2^2 \leq 1 \text{  , }\|v_{k}\|_2^2 \leq 1 \text{  and } z_k^n \geq 0~.
	\end{split}
	\end{equation}
	
	Here,
	\begin{itemize}
		\item $u_k \in \Rset^P$ is the spatial pattern of our atom
		\item $v_k \in \Rset^L$ is the temporal pattern of our atom
	\end{itemize}
\end{frame}

\begin{frame}{Optimization strategy}
\textbf{Tri-convex:} The problem is not jointly convex in $z^n_k$, $u_k$ and $v_k$ but it is convex in each block of coordinate.\\[1em]

We can use a block coordinate descent, aka alternate minimization, to converge to a local minima of this problem. The 3 following steps are applied alternatively:

\begin{itemize}
	\item \textbf{Z-step:} given a fixed estimate of the atom, compute the activation signal $z^n_k$ associated to each signal $X^n$.
	\item \textbf{u-step:} given a fixed estimate of the activation and temporal pattern, update the spatial pattern $u_k$.
	\item \textbf{v-step:} given a fixed estimate of the activation and spatial pattern, update the temporal pattern $v_k$.
\end{itemize}
\end{frame}

\begin{frame}{Z-step: Locally greedy coordinate descent (LGCD)}

$N$ independent problem such that
\[
	\label{eq:sparse_code}
	\min_{z_k^n \ge 0} \frac{1}{2} \left\|X^n - \sum_{k=1}^K z_k^n * D_k\right\|_2^2
	+ \lambda\sum_{k=1}^K\left\|z_k^n\right\|_1~.
\]
This problem is convex in $z_k$ and can be solved with different techniques:
\begin{itemize}
	\item Greedy CD \mycite{Kavukcuoglu2013}
	\item Fista \mycite{Chalasani2013}
	\item ADMM \mycite{Bristow2013}
	\item L-BFGS \mycite{Gramfort2017}
\end{itemize}

\strongpoint{These methods can be slow for long signals as the complexity of each iteration is at least linear in the length of the signal.}

\end{frame}

\begin{frame}[t]{Z-step: Locally greedy coordinate descent (LGCD)}
	
	For the Greedy Coordinate Descent, only 1 coordinate is updated at each iteration:
	\mycite{Kavukcuoglu2013}
	\vskip.5em
	\begin{enumerate}[<+->]\itemsep2em
		\item The coordinate $z_{k_0}[t_0]$ is updated to its optimal value $z'_{k_0}[t_0]$ when all other coordinate are fixed.
        \only<1>{
		\[
				z'_{k}[t] =  \max\left(\frac{\beta_{k}[t] - \lambda}{\| D_{k}\|_2^2}, 0\right) ,
		\]
		with $\beta_{k}[t] = \left[D_{k}^\Lsh * \left(X- \sum_{l=1}^K z_l * D_l +z_{k}[t]e_t* D_{k}\right)\right][t]$
        \vskip.5em
        For each coordinate update, it is possible to maintain the value of $\beta$ with $\mathcal O(KL)$ operations.
    }
		\item The updated coordinate is chosen 
	\end{enumerate}

    \only<2-3>{
        \setbeamercovered{%
            again covered={\opaqueness<1->{15}}}
        \begin{itemize}
            \item<2> Cyclic selection: $\mathcal{O}(1)$ \mycite{Friedman2007}
            \item<2> Randomized selection: $\mathcal{O}(1)$ \mycite{Nesterov2010}
            \item<2> Greedy selection: $\mathcal{O}(K\widetilde{T})$ \mycite{Osher2009}\\
            by maximizing $|z_k[t] - z'_k[t]|$
            \item<2-> Locally Greedy selection: $\mathcal{O}(KL)$ \mycite{Moreau2018}\\
            by maximizing $|z_k[t] - z'_k[t]|$ on a sub-segment.
        \end{itemize}
    }
	
\end{frame}


%\begin{frame}{Z-step: Locally greedy coordinate descent (LGCD)}
%
%\begin{columns}[T]
%	\column{.9\textwidth}
%	\begin{algorithm}[H]
%		\LinesNotNumbered
%		\SetKwInOut{Input}{Input}
%		\Input{Signal $X$, atoms $D_k$, number of segments $M$, stopping parameter $\epsilon >  0$, $z_k$ initialization}
%		Initialize $\beta_k[t]$\\ % and $z_k[t]$ for all $(k,t)$\\
%		\Repeat{$\|z - z'\|_\infty < \epsilon$ }{
%			\For{$m = 1$ \KwTo $M$}{
%				Compute $z'_{k}[t] =  \max\left(\frac{\beta_{k}[t]-\lambda}{\| D_{k}\|_2^2}, 0\right)$
%				for $(k,t) \in \mathcal C_m$ \\
%				Choose $\displaystyle(k_0, t_0) = \argmax_{(k, t)\in\mathcal C_m} |z_k[t] - z'_k[t]|$\\
%				Update $\beta$\\
%				Update the current point estimate $z_{k_0}[t_0]\leftarrow{}z'_{k_0}[t_0]$\\
%				%			Set max updates vector $\Delta_m = \left|z_{k_0}[t_0]^{(q+1)} - z'_{k_0}[t_0]\right|$~
%			}
%			
%		}
%		\caption{Locally greedy coordinate descent (LGCD)}
%		\label{alg:LGCD}
%	\end{algorithm}.
%\end{columns}
%
%\end{frame}


\begin{frame}{D-step: solving for the atoms}

The dictionary update is performed by minimizing
\begin{equation}
\min_{\|D_k\|_2 \leq 1} E(D) \overset{\Delta}{=} \sum_{n=1}^N\frac{1}{2}\|X^n - \sum_{k=1}^K z^n_k * D_k\|_{2}^{2} \hspace{6pt}
\enspace .
\end{equation}

Computing $\nabla_{d_k} E(\{d_k\}_k)$ can be done efficiently
\[
\nabla_{D} E(D)
= \sum_{n=1}^N (z_k^n)^\Lsh * \left(x^n - \sum_{l=1}^K z^n_l * D_l\right)
=  \Phi_k - \sum_{l=1}^K \Psi_{k, l} *  D_l \enspace ,
\]

\strongpoint{Save with Projected Gradient Descent (PGD) with an Armijo backtracking line-search for the D-step \mycite{Wright1999}.}

\end{frame}

\section{Experiments}
\begin{frame}[noframenumbering,t]
\vskip5em
\centering
\begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
	\usebeamerfont{title}\insertsectionhead%
\end{beamercolorbox}
\vskip5em
\flushleft
\large Good time to wake-up if you got lost in the previous section!
\end{frame}

\begin{frame}{Fast optimization}
Comparison with univariate methods on somato dataset with $T=134,700$, $K=8$ and $L=128$\\[1em]
\includegraphics[width=\textwidth]{all_last_0001_T_13470_P1_K8_L128}
\end{frame}

\begin{frame}{Fast optimization}
Comparison with multivariate methods on somato dataset with $T=134,700$, $K=8$, $P=5$ and $L=128$\\[1em]
\includegraphics[width=\textwidth]{all_last_0001_T_13470_P5_K8_L128}
\end{frame}

\begin{frame}{Good scaling in the number of channels $P$}
Scaling relative to $P$ on somato dataset with $T=134,700$, $K=2$, and $L=128$\\[1em]
\includegraphics[width=\textwidth]{scaling_channels_reg0_001_mean_rank1_K2_L128.pdf}
\end{frame}

\section{Experiments on MEG data}
\begin{frame}[noframenumbering,t]
\vskip5em
\centering
\begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
	\usebeamerfont{title}\insertsectionhead%
\end{beamercolorbox}
\vskip5em
\flushleft
\large Even better time to wake-up!
\end{frame}

\begin{frame}{MNE somatosensory data}
A selection of temporal waveforms of the atoms learned on the MNE sample dataset.\\[1em]
\centering
\includegraphics[height=0.7\textheight]{artifacts}
\end{frame}


\begin{frame}{MNE somatosensory data}
Atoms revealed using the MNE somatosensory data. Note the non-sinusoidal comb shape of the mu rhythm.\\[1em]
\centering
\includegraphics[height=.35\textheight]{atoms_somato_a}\hskip3em
\includegraphics[height=.35\textheight]{atoms_somato_b}\\[.3em]\hskip1em
\includegraphics[height=.35\textheight]{atoms_somato_c}\hskip3em
\includegraphics[height=.35\textheight]{atoms_somato_d}
\end{frame}

\begin{frame}{Conclusion}
	\begin{itemize}\itemsep1.5em
		\item We proposed a model for multivariate CSC with rank-1 constraint. This model makes sense for different type of data.
		\item We proposed a fast algorithm to solve the optimization problem involved in this model.
		\item We demonstrated numerically the performance of our algorithm on both simulated and real datasets.
		\item We illustrated the benefit of such method to study electromagnetic signals form recorded from brain activity. 
	\end{itemize}

\end{frame}



\begin{frame}{}
\vskip2em
{\centering
    \usebeamercolor[fg]{title}
    \usebeamerfont{title}
    \Huge \bf Thanks for your attention!\\[2em]}

Code available online:\\[1em]

\includegraphics[height=.8em]{github}~\textbf{alphacsc} :  alphacsc.github.io\\[1em]
\includegraphics[height=.8em]{github}~\textbf{DiCoDiLe} : github.com/tommoral/dicodile\\[2em]

Slides are on my web page:\\[1em]
\hskip5em\includegraphics[height=.8em]{website} tommoral.github.io
\hskip4em \includegraphics[height=.8em]{twitter} @tomamoral


\end{frame}

\appendix



\begin{frame}[noframenumbering]{Reference}
\tiny
\bibliography{../../library.bib}
\end{frame}

\begin{frame}[noframenumbering]{Locally Greedy Coordinate Descent \mycite{Moreau2018}}


We introduced the LGCD method which is an extension of GCD.\\
{
    \centering
    \inputTikZ{.7}{tikz/LGCD}
}

\only<1-2>{
    \vskip1em
    GCD has $\mathcal O(K\widetilde{T})$ computational complexity.\\[1em]
    \only<2>{But the update itself has complexity $\mathcal O(KL)$}
}
%
\visible<3->{
    With a partition $\mathcal C_m$ of the signal domain $[1, K]\times [0, \widetilde{T}[$,
    \[
    \mathcal C_m = [1, K]\times [\frac{(m-1)\widetilde{T}}{M}, \frac{m\widetilde{T}}{M}[
    \]%
}%
\visible<4->{%
    The coordinate to update is chosen greedily on a sub-domain $\mathcal C_m$\\[1em]
    
    {\centering$\frac{\widetilde{T}}{M} = 2L-1~~\Rightarrow~~\mathcal O$(Coordinate selection) = $\mathcal O$(Coordinate Update)\\[1em]}
    
    The overall iteration complexity is $\mathcal O(KL)$ instead of $\mathcal O(K\widetilde{T})$.
    \strongpoint{Efficient for sparse $Z$}
}


\end{frame}

\begin{frame}[noframenumbering]{D-step: solving for the atoms}

We use the projected gradient descent with an Armijo backtracking line-search \cite{Wright1999} for both u-step and v-step for
\begin{equation}
\begin{split}
\min_{\substack{\|u_{k}\|_2 \leq 1\\\|v_{k}\|_2 \leq 1}} E(u_k, v_k) \overset{\Delta}{=} \sum_{n=1}^N\frac{1}{2}\|X^n - \sum_{k=1}^K z^n_k * (u_k^{ }  v_k^\top) \|_{2}^{2} \hspace{6pt}
\enspace .
\end{split}
\end{equation}

One important computation trick is for fast computation of the gradient.
\[
\begin{split}
\nabla_{u_k} E(u_k, v_k) &=  \nabla_{D_k}E(u_k, v_k) v_k ~~ \in \Rset^{P}~,\\
\nabla_{v_k} E(u_k, v_k) &=  u_k^\top \nabla_{D_k} E(u_k, v_k)  ~~ \in \Rset^L~,
\end{split}
\]
Computing $\nabla_{D_k} E(u_k, v_k)$ can be done efficiently
\[
\nabla_{D_{k}} E(u_k, v_k) =  \sum_{n=1}^N (z_k^n)^\Lsh * \left(X^n - \sum_{l=1}^K z^n_l * D_l\right)
=  \Phi_k - \sum_{l=1}^K \Psi_{k, l} *  D_l \enspace ,
\]

\end{frame}


\begin{frame}[noframenumbering]{Pattern recovery}
Test the pattern recovery capabilities of our method on simulated data,
\[
X^n = \sum_{k=1}^2 z_k * (u_kv_k^\top) + \mathcal E
\]
where $(u_k, v_k)$ are chosen patterns of rank-1 and the activated coefficient $z^n_k[t]$ are drawn uniformly and their value are uniform in $[0, 1]$.\\[1em]
The noise $\mathcal E$ is generated as a gaussian white noise with variance $\sigma$.\\[1em]

We set $N=100$, $L=64$ and $\tT=640$
\end{frame}

\begin{frame}[noframenumbering]{Pattern recovery}
Patterns recovered with $P = 1$ and $P=5$. The signals were generated with the two simulated temporal patterns and with  $\sigma = 10^{-3}$. \\[1em]
\includegraphics[width=\textwidth]{1D_vs_multi_uv_hat_P5.pdf}
\end{frame}
\begin{frame}[noframenumbering]{Pattern recovery}
Evolution of the recovery loss with $\sigma$ for different values of $P$. Using more channels improves the recovery of the original patterns.\\[1em]
\includegraphics[width=\textwidth]{1D_vs_multi.pdf}
\end{frame}

\end{document}
